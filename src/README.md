# Agent LangChain Core avec RAG

Ce module contient un agent LangChain Core capable d'utiliser un syst√®me RAG (Retrieval-Augmented Generation) pour r√©pondre aux questions sur Dofus en interrogeant une base de connaissances vectorielle.

## üìÅ Structure

- **`rag_tool.py`** : Outil RAG qui encapsule la recherche vectorielle et la g√©n√©ration de r√©ponses
- **`agent.py`** : Agent LangChain Core (`RAGAgent`) qui utilise l'outil RAG
- **`example_usage.py`** : Exemples d'utilisation de l'agent
- **`__init__.py`** : Export du module principal

## üöÄ Utilisation rapide

### Utilisation basique (synchrone)

```python
from src.agent import RAGAgent

# Cr√©er un agent RAG
agent = RAGAgent()

# Poser une question
question = "Qu'est-ce que le dofus ocre et comment l'obtenir ?"
response = agent.invoke(question)
print(response)
```

### Utilisation asynchrone

```python
import asyncio
from src.agent import RAGAgent

async def main():
    agent = RAGAgent()
    question = "Donne-moi des informations sur les monstres de niveau 50."
    response = await agent.ainvoke(question)
    print(response)

asyncio.run(main())
```

### Utilisation avec streaming

```python
from src.agent import RAGAgent

agent = RAGAgent()
question = "Explique-moi comment fonctionne le syst√®me de qu√™tes."

for chunk in agent.stream(question):
    print(chunk, end="", flush=True)
```

### Utilisation avec la fonction helper

```python
from src.agent import create_agent

agent = create_agent()
response = agent.invoke("Quel est le meilleur √©quipement pour un niveau 100 ?")
```

## ‚öôÔ∏è Configuration

L'agent utilise automatiquement les configurations d√©finies dans `config.py` :

- **Connexion MongoDB** : Connexion locale √† la base de donn√©es `DPLN`
- **Vector Store** : Collection `Vector_store` avec index `vector_index`
- **Embeddings** : Mod√®le Mistral Embed (`mistral-embed`)
- **LLM** : Mod√®le Mistral (`magistral-small-latest`)
- **Prompt RAG** : Prompt depuis LangChain Hub (`rlm/rag-prompt-mistral`)

### Variables d'environnement requises

Les cl√©s API sont configur√©es dans `config.py` :
- `LANGSMITH_API_KEY` : Pour le tracing LangSmith
- `MISTRAL_API_KEY` : Pour les embeddings et le LLM Mistral
- `HF_TOKEN` : Token HuggingFace (optionnel)

## üõ†Ô∏è Personnalisation

### Personnaliser le LLM

```python
from src.agent import RAGAgent
from langchain.chat_models import init_chat_model

# Cr√©er un LLM personnalis√©
custom_llm = init_chat_model("autre-modele", model_provider="mistralai")

# Cr√©er un agent avec le LLM personnalis√©
agent = RAGAgent(llm=custom_llm)
```

### Personnaliser le prompt syst√®me

```python
from src.agent import RAGAgent

custom_prompt = """Tu es un expert en Dofus sp√©cialis√© dans les qu√™tes.
R√©ponds toujours de mani√®re d√©taill√©e et pr√©cise."""

agent = RAGAgent(system_prompt=custom_prompt)
```

### Ajouter des outils suppl√©mentaires

```python
from src.agent import RAGAgent
from langchain_core.tools import tool

@tool
def calculer_damage(attaque: int, defense: int) -> str:
    """Calcule les d√©g√¢ts inflig√©s."""
    damage = max(1, attaque - defense)
    return f"D√©g√¢ts inflig√©s: {damage}"

agent = RAGAgent(tools=[calculer_damage])
# L'outil RAG est automatiquement ajout√©
```

### Personnaliser l'outil RAG

```python
from src.rag_tool import RAGTool, get_rag_tool
from src.agent import RAGAgent

# Personnaliser l'outil RAG (plus de documents r√©cup√©r√©s)
rag_tool_instance = RAGTool(k=8)  # R√©cup√®re 8 documents au lieu de 4

# Note: L'agent utilise automatiquement l'instance globale via get_rag_tool()
# Pour utiliser une instance personnalis√©e, vous devrez modifier rag_tool.py
```

## üìö API de l'agent

### Classe `RAGAgent`

#### Constructeur

```python
RAGAgent(
    llm=None,                    # Mod√®le de langage (optionnel)
    tools=None,                  # Liste d'outils suppl√©mentaires (optionnel)
    system_prompt=None           # Prompt syst√®me personnalis√© (optionnel)
)
```

#### M√©thodes

- **`invoke(message: str, **kwargs) -> str`** : Ex√©cute l'agent de mani√®re synchrone
- **`ainvoke(message: str, **kwargs) -> str`** : Ex√©cute l'agent de mani√®re asynchrone
- **`stream(message: str, **kwargs) -> Iterator`** : Stream la r√©ponse de l'agent

## üîç Fonctionnement interne

1. **R√©ception de la question** : L'agent re√ßoit une question de l'utilisateur
2. **Appel du LLM** : Le LLM d√©cide s'il doit utiliser l'outil RAG
3. **Recherche vectorielle** : Si n√©cessaire, l'outil RAG effectue une recherche dans MongoDB
4. **G√©n√©ration** : Le LLM g√©n√®re une r√©ponse bas√©e sur les documents r√©cup√©r√©s
5. **Retour** : La r√©ponse finale est retourn√©e √† l'utilisateur

### Flux de traitement des outils

L'agent g√®re automatiquement les appels d'outils multiples :
- Si le LLM d√©cide d'appeler un outil, celui-ci est ex√©cut√©
- Les r√©sultats sont ajout√©s au contexte
- Le LLM est r√©invit√© avec les r√©sultats pour g√©n√©rer la r√©ponse finale

## üìù Exemples d'utilisation

Voir le fichier `example_usage.py` pour des exemples complets d'utilisation.

## üîó D√©pendances

- `langchain` / `langchain-core`
- `langchain-mongodb`
- `langchain-mistralai`
- `pymongo`
- `config.py` (fichier de configuration du projet)

## ‚ö†Ô∏è Notes importantes

- L'agent n√©cessite une connexion MongoDB active
- Le vector store doit √™tre pr√©alablement peupl√© avec des documents
- Les cl√©s API doivent √™tre configur√©es dans `config.py`
- L'outil RAG utilise une instance globale (singleton) pour optimiser les performances

## üêõ D√©pannage

### Erreur de connexion MongoDB

Assurez-vous que MongoDB est d√©marr√© et que la cha√Æne de connexion dans `config.py` est correcte.

### Erreur d'API

V√©rifiez que les cl√©s API dans `config.py` sont valides et que les variables d'environnement sont correctement d√©finies.

### Aucun document trouv√©

V√©rifiez que le vector store contient des documents et que l'index `vector_index` existe dans MongoDB.

